{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the csv file into a panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"CarPrice_Assignment.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before we begin linear regression, we must pre-process the data to make it more suitable for the regression model to work on \n",
    "### Using correlation matrix to drop irrelevant and highly correlated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num = data.select_dtypes(include=['number'])\n",
    "plt.figure(figsize=(12,10))\n",
    "cor = data_num.corr()\n",
    "sns.heatmap(cor, annot=True, cmap = 'viridis')\n",
    "def correlationfeattofeat(dataset, threshold = 0.9):\n",
    "    column_cor = set()\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i,j]) > threshold:\n",
    "                colname = corr_matrix.columns[i]\n",
    "                column_cor.add(colname)\n",
    "    return column_cor\n",
    "def correlationfeattotarget(dataset, threshold = 0.1):\n",
    "    column_cor = set()\n",
    "    corr_matrix = dataset.corr()\n",
    "    for col in corr_matrix.columns:\n",
    "        if abs(corr_matrix.loc['price', col]) < threshold:\n",
    "            column_cor.add(col)\n",
    "    return column_cor\n",
    "\n",
    "corr_features_irrelevant = correlationfeattotarget(data_num)\n",
    "print(corr_features_irrelevant)\n",
    "corr_features_correlating = correlationfeattofeat(data_num)\n",
    "print(corr_features_correlating)\n",
    "data_num_proc1 = data_num.drop(corr_features_irrelevant, axis=1)\n",
    "data_num_proc2 = data_num_proc1.drop(corr_features_correlating, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing encoding with categorical data, standardization with numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_num_proc3 = data_num_proc2.drop(['price','car_ID' ], axis=1)  # replace 'target_variable' with your actual target variable\n",
    "y = data['price']\n",
    "data_cat =data.select_dtypes(include=['object'])  \n",
    "mean = data_num_proc3.mean(axis=0)\n",
    "std = data_num_proc3.std(axis=0)\n",
    "data_num_norm = (data_num_proc3 - mean) / std\n",
    "\n",
    "data_cat_proc = pd.get_dummies(data_cat, drop_first=True) \n",
    "boolean_cols = data_cat_proc.columns[data_cat_proc.dtypes == 'bool']\n",
    "data_cat_proc[boolean_cols] = data_cat_proc[boolean_cols].astype(int)\n",
    "data_proc = pd.concat([data_num_norm, data_cat_proc], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting given data into a dataset for training and another for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_size = 0.3\n",
    "\n",
    "n_samples = data_proc.shape[0]\n",
    "\n",
    "n_test_samples = int(n_samples * test_size)\n",
    "print(n_test_samples)\n",
    "\n",
    "indices = np.arange(n_samples)\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_indices = indices[n_test_samples:]\n",
    "test_indices = indices[:n_test_samples]\n",
    "\n",
    "X_train = data_proc.iloc[train_indices]\n",
    "y_train = y.iloc[train_indices]\n",
    "\n",
    "\n",
    "X_test = data_proc.iloc[test_indices]\n",
    "y_test = y.iloc[test_indices]\n",
    "mse_values = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Linear Regression\n",
    "### Creating a class LinearRegression, setting its properties and defining its functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    def __init__(self, lr = 0.01, n_iters = 600):\n",
    "        self.lr = lr\n",
    "        self.n_iters = n_iters\n",
    "        self.weights = None\n",
    "        self.bias = 0\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "        self.weights = np.zeros(n_features)\n",
    "        self.bias = 0\n",
    "        prev_mse = float('inf')\n",
    "        for i in range(self.n_iters):\n",
    "            y_predicted = np.dot(X, self.weights) + self.bias\n",
    "            delw = (1/n_samples)*np.dot(X.T, (y_predicted - y))\n",
    "            delb = (1/n_samples)*np.sum(y_predicted - y)\n",
    "            self.weights = self.weights - self.lr*delw\n",
    "            self.bias = self.bias - self.lr*delb\n",
    "            mse = np.mean((y_predicted - y) ** 2)\n",
    "            mse_values.append(mse)\n",
    "            if i > 0:\n",
    "                if prev_mse - mse < 1e3:\n",
    "                    break\n",
    "            prev_mse = mse\n",
    "    def predict(self, X):\n",
    "        y_predicted = np.dot(X, self.weights) + self.bias\n",
    "        return y_predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Object to run linear regression on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train,y_train)\n",
    "predictions = regressor.predict(X_test)\n",
    "print(predictions)\n",
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel('Actual Prices')\n",
    "plt.ylabel('Predicted Prices')\n",
    "plt.title('Actual vs Predicted Prices')\n",
    "plt.plot([min(y_test), max(predictions)], [min(y_test), max(predictions)], 'k:')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depiction of change in MSE over iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mse_values)\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Mean Square Error')\n",
    "plt.title('MSE vs Iteration')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating R2 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "total_sum = np.sum((y_test - np.mean(y_test)) ** 2)\n",
    "residual_sum = np.sum((y_test - predictions) ** 2)\n",
    "r2 = 1 - (residual_sum/total_sum)\n",
    "print(r2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
